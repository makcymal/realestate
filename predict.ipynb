{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import (\n",
    "  is_numeric_dtype,\n",
    "  is_integer_dtype,\n",
    "  is_float_dtype,\n",
    ")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import (\n",
    "  MinMaxScaler,\n",
    "  StandardScaler,\n",
    "  RobustScaler,\n",
    "  LabelEncoder,\n",
    "  # OrdinalEncoder,\n",
    "  TargetEncoder,\n",
    ")\n",
    "from category_encoders import (\n",
    "  BinaryEncoder,\n",
    "  OrdinalEncoder,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "  mean_squared_error as mse,\n",
    "  mean_absolute_error as mae,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "rng = np.random.default_rng(424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframe according to the provided dtypes\n",
    "df_dtypes = pd.read_csv(\"data/df_dtypes.csv\", index_col=\"Column\")\n",
    "df_dtypes_dict = df_dtypes.to_dict()[\"Dtype\"]\n",
    "del df_dtypes_dict[\"DtPayAcc\"]\n",
    "del df_dtypes_dict[\"DtIns\"]\n",
    "df = pd.read_csv(\n",
    "  \"data/df.csv\",\n",
    "  parse_dates=[\"DtPayAcc\", \"DtIns\"],\n",
    "  dtype=df_dtypes_dict,\n",
    "  index_col=\"HouseId\",\n",
    ").replace({\"Другой\": pd.NA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CemeteryNrby\", \"NarcoDispNrby\", \"Latitude\", \"Longitude\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sort columns (remainder=\"passthrough\" in ColumnTransformer requires identical order)\n",
    "2. encode categoricals with simple label encoding (as KNNImputer requires)\n",
    "3. scale numerical columns (as KNNImputer requires)\n",
    "4. impute missing values with KNNImputer\n",
    "5. scale back numerical categoricals\n",
    "6. round numerical categoricals to possible values\n",
    "6. encode numerical categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns to be target encoded\n",
    "cat_tar_enc_cols = [\"CompanyName\"]\n",
    "# categorical columns to be ordinal encoded\n",
    "cat_ord_enc_cols = [\"District\", \"HouseCatg\"]\n",
    "# categorical columns to be binary encoded\n",
    "cat_bin_enc_cols = [\n",
    "  # too much NAs, drop it\n",
    "  \"FacadeMainMatrl\",  # \"Другой\" - 42%\n",
    "  \"FacadeAuxlMatrl\",  # \"Другой\" - 27%\n",
    "  \"FacadeType\",\n",
    "  \"HouseType\",\n",
    "]\n",
    "cat_cols = cat_tar_enc_cols + cat_ord_enc_cols + cat_bin_enc_cols\n",
    "\n",
    "# numerical columns to be scaled\n",
    "num_cols = df.dtypes[df.dtypes.map(is_numeric_dtype)].index.to_list()\n",
    "num_cols.remove(\"SoldFlatsArea\")\n",
    "num_cols.remove(\"SoldFlatsRubl\")\n",
    "num_cols.remove(\"SqMeterCost\")\n",
    "num_cols.sort()\n",
    "\n",
    "# boolean columns that shouldn't be scaled\n",
    "bool_cols = []\n",
    "for col in num_cols:\n",
    "  if 0 <= df[col].min() and df[col].max() <= 1:\n",
    "    bool_cols.append(col)\n",
    "bool_cols.sort()\n",
    "\n",
    "for col in bool_cols:\n",
    "  num_cols.remove(col)\n",
    "\n",
    "# target column also should be scaled (logarithm)\n",
    "target_col = [\"SqMeterCost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cols = target_col + cat_cols + num_cols + bool_cols\n",
    "df = df[sorted_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_enc = OrdinalEncoder()\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "  [(\"scaler\", MinMaxScaler(), cat_cols + num_cols)],\n",
    "  remainder=\"passthrough\",\n",
    "  verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "  [\n",
    "    (\"first_enc\", first_enc),\n",
    "    (\"scaler\", scaler),\n",
    "    (\"imputer\", KNNImputer(missing_values=np.nan)),\n",
    "  ]\n",
    ")\n",
    "\n",
    "piped_df = pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(\n",
    "  model, n_folds: int, X: pd.DataFrame, y: pd.Series, metrics=None\n",
    ") -> np.ndarray:\n",
    "\n",
    "  kfold = KFold(n_folds, shuffle=True)\n",
    "  if not metrics:\n",
    "    metrics = [{\"name\": \"mse\", \"func\": mse}, {\"name\": \"mae\", \"func\": mae}]\n",
    "  cvscores = np.zeros(\n",
    "    shape=n_folds, dtype=[(metric[\"name\"], \"float\") for metric in metrics]\n",
    "  )\n",
    "\n",
    "  for i, (train, test) in enumerate(kfold.split(X, y)):\n",
    "    model.fit(X.iloc[train], y.iloc[train])\n",
    "    y_pred = model.predict(X.iloc[test])\n",
    "    y_true = y.iloc[test]\n",
    "    for metric in metrics:\n",
    "      cvscores[metric[\"name\"]][i] = metric[\"func\"](y_true, y_pred)\n",
    "\n",
    "  return cvscores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
