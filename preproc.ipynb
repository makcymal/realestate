{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preproc import apply_dtype_tfrm, INT_DTYPE, FLOAT_DTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data here needs to be named properly (in english)\n",
    "# converted to proper dtypes, imputed, encoded and then merged\n",
    "raw_houses = pd.read_csv(\"data/raw_houses.csv\")\n",
    "raw_sells = pd.read_csv(\"data/raw_sells.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial df was transposes and had houses as columns\n",
    "houses = raw_houses.transpose()\n",
    "houses.columns = houses.iloc[0]\n",
    "houses.index = pd.RangeIndex(0, len(houses.index))\n",
    "\n",
    "# rename columns, convert to proper dtypes\n",
    "ft_houses = pd.read_csv(\"data/features_houses.csv\", index_col=\"Old\")\n",
    "houses = houses[1:].rename(columns=ft_houses[\"New\"]).reset_index(drop=True)\n",
    "ft_houses = ft_houses.reset_index().set_index(\"New\")\n",
    "houses = apply_dtype_tfrm(houses, ft_houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns, convert to proper dtypes\n",
    "ft_sells = pd.read_csv(\"data/features_sells.csv\", index_col=\"Old\")\n",
    "sells = raw_sells.rename(columns=ft_sells[\"New\"])\n",
    "ft_sells = ft_sells.reset_index().set_index(\"New\")\n",
    "sells = apply_dtype_tfrm(sells, ft_sells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "houses_drops = [\n",
    "  \"SqMeterCost\",\n",
    "  \"SoldNFlats\",\n",
    "  \"SoldFlatsArea\",\n",
    "  \"SoldFlatsRubl\",\n",
    "  \"SoldNParkSlots\",\n",
    "  \"SoldNNonresid\",\n",
    "  \"SoldPercent\",\n",
    "  \"SeaView\",\n",
    "  \"DtInfo\",\n",
    "  \"DtPayAcc\",\n",
    "  \"DtIns\",\n",
    "  \"Latitude\",\n",
    "  \"Longitude\",\n",
    "  \"NrbyCemetery\",\n",
    "  \"NrbyNarcoDisp\",\n",
    "]\n",
    "houses.drop(columns=houses_drops, inplace=True, errors=\"ignore\")\n",
    "\n",
    "sells_drops = [\n",
    "  \"SoldNFlats\",\n",
    "  \"SoldNParkSlots\",\n",
    "  \"SoldParkSlotsArea\",\n",
    "  \"SoldParkSlotsRubl\",\n",
    "  \"SoldNNonresid\",\n",
    "  \"SoldNonresidArea\",\n",
    "  \"SoldNonresidRubl\",\n",
    "  \"RowIndex\",\n",
    "  \"Region\",\n",
    "  \"InfoMonth\",\n",
    "]\n",
    "sells.drop(columns=sells_drops, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave only VDK real estate\n",
    "if \"Settlement\" in sells.columns:\n",
    "  sells = sells[sells[\"Settlement\"] == \"Владивосток\"].drop(\n",
    "    columns=[\"Settlement\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to group rows by\n",
    "groupby_cols = [\n",
    "  \"ProjectId\",\n",
    "  \"HouseId\",\n",
    "  \"CompanyName\",\n",
    "  \"HouseName\",\n",
    "  \"HouseCatg\",\n",
    "  \"HouseStat\",\n",
    "]\n",
    "# columns to sum over\n",
    "sum_cols = [\"SoldFlatsArea\", \"SoldFlatsRubl\"]\n",
    "# all the output sells columns\n",
    "sells_cols = groupby_cols + sum_cols\n",
    "sells = sells[sells_cols].groupby(by=groupby_cols, as_index=False).sum()\n",
    "\n",
    "# avoid division by zero: np.nan propagates\n",
    "sells[\"SoldFlatsArea\"] = (\n",
    "  sells[\"SoldFlatsArea\"]\n",
    "  .map(lambda x: np.nan if x == 0.0 else x)\n",
    "  .astype(FLOAT_DTYPE)\n",
    ")\n",
    "sells[\"SqMeterCost\"] = (\n",
    "  sells[\"SoldFlatsRubl\"] / sells[\"SoldFlatsArea\"]\n",
    ").astype(FLOAT_DTYPE)\n",
    "sells.set_index(\"HouseId\", inplace=True)\n",
    "\n",
    "# drop missing SqMeterCost\n",
    "sells.dropna(axis=0, subset=[\"SqMeterCost\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to merge two tables using sells[\"HouseId\", \"HouseName\"] and houses[[\"Name\"]]\n",
    "# some houses[\"Name\"] are in form of \"{Name or Address} {HouseId}\"\n",
    "# but a few of them doesn't have {HouseId}\n",
    "# HouseId >= 3062 if exists so we can clearly separate it from the first part\n",
    "def pop_house_id(name: str) -> tuple[str, int]:\n",
    "  sep = name.rfind(\" \")\n",
    "  if sep == -1:\n",
    "    return name, pd.NA\n",
    "\n",
    "  try:\n",
    "    project_id = int(name[sep + 1 :])\n",
    "    if project_id < 3062:\n",
    "      raise Exception\n",
    "  except:\n",
    "    return name, pd.NA\n",
    "\n",
    "  return name[:sep], project_id\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/16236684/apply-pandas-function-to-column-to-create-multiple-new-columns\n",
    "houses[\"HouseName\"], houses[\"HouseId\"] = zip(\n",
    "  *houses[\"Name\"].map(pop_house_id)\n",
    ")\n",
    "houses[\"HouseId\"] = houses[\"HouseId\"].astype(INT_DTYPE)\n",
    "houses.drop(columns=[\"Name\"], inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map NA houses.HouseId to valid sells.HouseId\n",
    "na_mapping = {\n",
    "  \"Садгород-357\": [44295],\n",
    "  \"Садгород-295\": [44295],\n",
    "  # 'Времена года': -1,     # wtf\n",
    "  \"Восточный ЛУЧ-5\": [\n",
    "    37381,\n",
    "    37701,\n",
    "    37703,\n",
    "    37704,\n",
    "    37705,\n",
    "    34275,\n",
    "    37333,\n",
    "    36352,\n",
    "  ],\n",
    "  \"Новые горизонты\": [40959, 42989],\n",
    "  \"Басаргина, д. 2\": [41333],\n",
    "  \"Басаргина, д. 2, б/с 2 10 эт\": [41422],\n",
    "  \"Басаргина, д. 2, б/с 2 18 эт\": [41487],\n",
    "  \"Борисенко, д. 100, лит. Е\": [38128, 38129],\n",
    "  \"Изумрудный, 1оч\": [13283, 13284, 13285, 37526, 37527],\n",
    "}\n",
    "\n",
    "if any(pd.isna(houses[\"HouseId\"])):\n",
    "  for house_name, house_id in na_mapping.items():\n",
    "    rows = []\n",
    "    for i in range(len(house_id)):\n",
    "      row = houses[houses[\"HouseName\"] == house_name].copy()\n",
    "      row[\"HouseId\"] = house_id[i]\n",
    "      rows.append(row)\n",
    "      # break # if identical rows shouldn't map to possibly different targets\n",
    "    houses = pd.concat([houses, *rows], ignore_index=True)\n",
    "\n",
    "  houses.dropna(axis=0, subset=[\"HouseId\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sells.drop(\n",
    "  columns=[\"HouseName\", \"ProjectId\", \"SoldFlatsArea\", \"SoldFlatsRubl\"],\n",
    "  inplace=True,\n",
    "  errors=\"ignore\",\n",
    ")\n",
    "houses.drop(columns=\"HouseName\", inplace=True, errors=\"ignore\")\n",
    "houses.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only common column is \"HouseId\"\n",
    "df = pd.merge(\n",
    "  left=sells, right=houses, on=\"HouseId\", suffixes=[\"\", \"_right\"]\n",
    ").set_index(\"HouseId\", drop=True)\n",
    "df.to_csv(\"data/df.csv\")\n",
    "\n",
    "df_dtypes = df.dtypes\n",
    "df_dtypes.index.name = \"Column\"\n",
    "df_dtypes.rename(\"Dtype\", inplace=True)\n",
    "df_dtypes.to_csv(\"data/df_dtypes.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
