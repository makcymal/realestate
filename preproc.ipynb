{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data here needs to be named properly (in english)\n",
    "# converted to proper dtypes, imputed, encoded and then merged\n",
    "raw_houses = pd.read_csv(\"data/raw_houses.csv\")\n",
    "raw_sells = pd.read_csv(\"data/raw_sells.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse inconsistent floats, booleans, convert to proper dtypes\n",
    "def apply_dtype_trfmer(\n",
    "  X: pd.DataFrame, features: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "  int_ft = features.index[features[\"Dtype\"] == \"int\"]\n",
    "  float_ft = features.index[features[\"Dtype\"] == \"float\"]\n",
    "  datetime_ft = features.index[features[\"Dtype\"] == \"datetime\"]\n",
    "  boolean_ft = features.index[features[\"Dtype\"] == \"boolean\"]\n",
    "\n",
    "  dtype_trfmer = ColumnTransformer(\n",
    "    [\n",
    "      (\"int_trfm\", IntTransformer(), int_ft),\n",
    "      (\"float_trfm\", FloatTransformer(), float_ft),\n",
    "      (\"datetime_trfm\", DatetimeTransformer(), datetime_ft),\n",
    "      (\"boolean_trfm\", BooleanTransformer(), boolean_ft),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    "  )\n",
    "  dtype_trfmer.set_output(transform=\"pandas\")\n",
    "  return dtype_trfmer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial df was transposes and had houses as columns\n",
    "houses = raw_houses.transpose()\n",
    "houses.columns = houses.iloc[0]\n",
    "houses.index = pd.RangeIndex(0, len(houses.index))\n",
    "\n",
    "# rename columns, convert to proper dtypes\n",
    "ft_houses = pd.read_csv(\"data/features_houses.csv\", index_col=\"Old\")\n",
    "houses = houses[1:].rename(columns=ft_houses[\"New\"]).reset_index(drop=True)\n",
    "ft_houses = ft_houses.reset_index().set_index(\"New\")\n",
    "houses = apply_dtype_trfmer(houses, ft_houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns, convert to proper dtypes\n",
    "ft_sells = pd.read_csv(\"data/features_sells.csv\", index_col=\"Old\")\n",
    "sells = raw_sells.rename(columns=ft_sells[\"New\"])\n",
    "ft_sells = ft_sells.reset_index().set_index(\"New\")\n",
    "sells = apply_dtype_trfmer(sells, ft_sells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to merge two tables using sells[\"HouseId\", \"HouseName\"] and houses[[\"Name\"]]\n",
    "# some houses[\"Name\"] are in form of \"{Name or Address} {HouseId}\"\n",
    "# but a few of them doesn't have {HouseId}\n",
    "# HouseId >= 3062 if exists so we can clearly separate it from the first part\n",
    "def pop_project_id(name: str) -> tuple[str, int]:\n",
    "  sep = name.rfind(\" \")\n",
    "  if sep == -1:\n",
    "    return name, pd.NA\n",
    "\n",
    "  try:\n",
    "    project_id = int(name[sep + 1 :])\n",
    "    if project_id < 3062:\n",
    "      raise Exception\n",
    "  except:\n",
    "    return name, pd.NA\n",
    "\n",
    "  return name[:sep], project_id\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/16236684/apply-pandas-function-to-column-to-create-multiple-new-columns\n",
    "houses[\"HouseName\"], houses[\"HouseId\"] = zip(\n",
    "  *houses[\"Name\"].map(pop_project_id)\n",
    ")\n",
    "houses[\"HouseId\"] = houses[\"HouseId\"].astype(\"Int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop uninstresting data\n",
    "houses_drops = (\n",
    "  [\"Name\", \"SeaView\", \"InfoDate\", \"SoldFlatsRubl\", \"NSoldFlats\"]\n",
    "  + [\"NSoldParkSlots\", \"SoldFlatsArea\", \"SoldPercent\"]\n",
    "  + [\"MeanSqMeterCost\", \"NSoldNonresid\"]\n",
    ")\n",
    "houses.drop(columns=houses_drops, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# predict only Vladivostok real estate prices\n",
    "if \"Settlement\" in sells.columns:\n",
    "  sells = sells[sells[\"Settlement\"] == \"Владивосток\"].reset_index(drop=True)\n",
    "# sum up sells for each house over months\n",
    "sells_groupby = [\n",
    "  # \"ProjectId\",  # doesn't appear in houses.Name\n",
    "  \"HouseId\",\n",
    "  \"CompanyName\",\n",
    "  \"HouseName\",\n",
    "  \"HouseCatg\",\n",
    "  \"HouseStatus\",\n",
    "]\n",
    "# perhaps columns like SoldNonresid, SoldParkSlots cannot be predicting features\n",
    "sells_cols = sells_groupby + [\"SoldFlatsArea\", \"SoldFlatsRubl\"]\n",
    "# sum over aug 2021-aug 2022\n",
    "sells = sells[sells_cols].groupby(by=sells_groupby, as_index=False).sum()\n",
    "\n",
    "# target\n",
    "# avoid division by zero: pd.NA propagates\n",
    "sells[\"SoldFlatsArea\"] = (\n",
    "  sells[\"SoldFlatsArea\"]\n",
    "  .map(lambda x: np.nan if x == 0.0 else x)\n",
    "  .astype(\"Float32\")\n",
    ")\n",
    "sells[\"SoldFlatsRubl\"] = sells[\"SoldFlatsRubl\"].astype(\"Int32\")\n",
    "sells[\"SqMeterCost\"] = (\n",
    "  sells[\"SoldFlatsRubl\"] / sells[\"SoldFlatsArea\"]\n",
    ").astype(\"Float32\")\n",
    "sells.set_index(\"HouseId\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cant believe in SqMeterCost == 32148\n",
    "def drop_outliers(sells: pd.DataFrame, tail: float) -> pd.DataFrame:\n",
    "  lower = sells[\"SqMeterCost\"].quantile(tail, interpolation=\"lower\")\n",
    "  higher = sells[\"SqMeterCost\"].quantile(1 - tail, interpolation=\"higher\")\n",
    "  return sells[\n",
    "    (sells[\"SqMeterCost\"] >= lower) & (sells[\"SqMeterCost\"] <= higher)\n",
    "  ]\n",
    "\n",
    "\n",
    "# unreliable data\n",
    "if sells[\"SqMeterCost\"].min() < 50000:\n",
    "  sells = drop_outliers(sells, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map NA houses.HouseId to valid sells.HouseId\n",
    "na_mapping = {\n",
    "  \"Садгород-357\": 44295,\n",
    "  \"Садгород-295\": 44295,\n",
    "  # 'Времена года': -1,     # wtf\n",
    "  \"Восточный ЛУЧ-5\": [\n",
    "    37381,\n",
    "    37701,\n",
    "    37703,\n",
    "    37704,\n",
    "    37705,\n",
    "    34275,\n",
    "    37333,\n",
    "    36352,\n",
    "  ],\n",
    "  \"Новые горизонты\": [40959, 42989],\n",
    "  \"Басаргина, д. 2\": 41333,\n",
    "  \"Басаргина, д. 2, б/с 2 10 эт\": 41422,\n",
    "  \"Басаргина, д. 2, б/с 2 18 эт\": 41487,\n",
    "  \"Борисенко, д. 100, лит. Е\": [38128, 38129],\n",
    "  \"Изумрудный, 1оч\": [13283, 13284, 13285, 37526, 37527],\n",
    "}\n",
    "\n",
    "for house_name, house_id in na_mapping.items():\n",
    "  if isinstance(house_id, list):\n",
    "    rows = []\n",
    "    for i in range(len(house_id)):\n",
    "      row = houses[houses[\"HouseName\"] == house_name].copy()\n",
    "      row[\"HouseId\"] = house_id[i]\n",
    "      rows.append(row)\n",
    "    houses = pd.concat([houses, *rows], ignore_index=True)\n",
    "  else:\n",
    "    houses.loc[houses[\"HouseName\"] == house_name, \"HouseId\"] = house_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "  pd.merge(left=sells, right=houses, on=\"HouseId\", suffixes=[\"\", \"_right\"])\n",
    "  .set_index(\"HouseId\", drop=True)\n",
    "  .drop(columns=[\"HouseName_right\"])\n",
    ")\n",
    "df.to_csv(\"data/df.csv\")\n",
    "\n",
    "df_dtypes = df.dtypes\n",
    "df_dtypes.index.name = \"Column\"\n",
    "df_dtypes.rename(\"Dtype\", inplace=True)\n",
    "df_dtypes.to_csv(\"data/df_dtypes.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
